#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ¯æ—¥ Log åˆ†æå·¥å…·

è§£æ logs/ ç›®éŒ„ä¸‹çš„æ‰€æœ‰ log æª”æ¡ˆï¼Œç”¢å‡ºçµæ§‹åŒ–çš„æ¯æ—¥åŸ·è¡Œå ±å‘Šã€‚

ç”¨æ³•:
    python analyze_logs.py              # åˆ†ææ‰€æœ‰ log
    python analyze_logs.py 2026-02-06   # åˆ†ææŒ‡å®šæ—¥æœŸ
    python analyze_logs.py --latest     # åªåˆ†ææœ€æ–°ä¸€å¤©

@author: rubylintu
"""

import os
import re
import sys
import glob
from datetime import datetime
from collections import defaultdict

SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
LOG_DIR = os.path.join(SCRIPT_DIR, 'logs')

# â”€â”€â”€ æ­£è¦è¡¨é”å¼ â”€â”€â”€

# æ¨™æº– log è¡Œ: 2026-02-06 11:40:57,687 - INFO - message
RE_LOG_LINE = re.compile(
    r'^(\d{4}-\d{2}-\d{2}) (\d{2}:\d{2}:\d{2}),\d+ - (\w+) - (.+)$'
)

# è‚¡åƒ¹æŠ“å–: [2/31] æ™¯ç¢©(3189): $263.5000  æˆ–  $-
RE_STOCK_PRICE = re.compile(
    r'\[(\d+)/(\d+)\] (.+?)\((\d+)\): \$(.+)'
)

# æŠ“å–å¤±æ•—: æŠ“å– ç¾¤è¯ å¤±æ•—: 'n'
RE_FETCH_ERROR = re.compile(
    r'æŠ“å– (.+?) å¤±æ•—: (.+)'
)

# æ–°èè™•ç†: [1/31] è™•ç†: ç¾¤è¯ (8299)
RE_NEWS_PROCESS = re.compile(
    r'\[(\d+)/(\d+)\] è™•ç†: (.+?) \((\d+)\)'
)

# æ–°èçµæœ: æ‰¾åˆ° N å‰‡æ–°æ–°è
RE_NEWS_FOUND = re.compile(
    r'æ‰¾åˆ° (\d+) å‰‡æ–°æ–°è'
)

# è‚¡åƒ¹æ¼²è·Œ: è‚¡åƒ¹: 263.5, æ¼²è·Œ: -2.59%
RE_STOCK_CHANGE = re.compile(
    r'è‚¡åƒ¹: ([\d.]+), æ¼²è·Œ: ([+-]?[\d.]+)%'
)

# GPT åˆ†æ: GPT ç›¤å‰åˆ†æ ç¾¤è¯: æ¼² (70%)  æˆ–  GPT åˆ†æ ç¾¤è¯: ä¸­æ€§ (50%)
RE_GPT_ANALYSIS = re.compile(
    r'GPT (?:ç›¤å‰)?åˆ†æ (.+?): (.+?) \((\d+)%\)'
)

# ç›£æ§è¿­ä»£: å·²åŸ·è¡Œ 10 æ¬¡ï¼Œæ™‚é–“: 11:50:41
RE_MONITOR_ITER = re.compile(
    r'å·²åŸ·è¡Œ (\d+) æ¬¡ï¼Œæ™‚é–“: (\d{2}:\d{2}:\d{2})'
)

# ç›¤å¾Œæº–ç¢ºç‡: ç›¤å¾Œåˆ†æå®Œæˆï¼Œæº–ç¢ºç‡ 31.2%
RE_POSTMARKET_ACC = re.compile(
    r'ç›¤å¾Œåˆ†æå®Œæˆï¼Œæº–ç¢ºç‡ ([\d.]+)%'
)

# ç›¤å‰é æ¸¬å®Œæˆ: ç›¤å‰åˆ†æå®Œæˆï¼Œé æ¸¬ 30 æª”è‚¡ç¥¨
RE_PREMARKET_DONE = re.compile(
    r'ç›¤å‰åˆ†æå®Œæˆï¼Œé æ¸¬ (\d+) æª”è‚¡ç¥¨'
)

# ç›£æ§çµæŸ: å³æ™‚ç›£æ§çµæŸï¼Œå…±åŸ·è¡Œ N æ¬¡
RE_MONITOR_END = re.compile(
    r'å³æ™‚ç›£æ§çµæŸï¼Œå…±åŸ·è¡Œ (\d+) æ¬¡'
)

# Discord é€šçŸ¥
RE_DISCORD = re.compile(r'Discord é€šçŸ¥å·²ç™¼é€')

# æ³•äººè³‡æ–™ (cron.log éæ¨™æº–æ ¼å¼)
RE_INSTITUTIONAL = re.compile(
    r'å–å¾— (\d+) æª”è‚¡ç¥¨æ³•äººè³‡æ–™ \((\d+)\)'
)

# SyntaxError (éæ¨™æº–æ ¼å¼)
RE_SYNTAX_ERROR = re.compile(r'SyntaxError')


def parse_log_file(filepath):
    """è§£æå–®ä¸€ log æª”æ¡ˆï¼Œå›å‚³çµæ§‹åŒ–è³‡æ–™"""
    results = {
        'file': os.path.basename(filepath),
        'sessions': [],  # æ¯æ¬¡ç¨‹å¼å•Ÿå‹•ç‚ºä¸€å€‹ session
        'errors': [],
        'warnings': [],
        'raw_lines': 0,
    }

    current_session = None

    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            lines = f.readlines()
    except Exception as e:
        results['errors'].append(f'ç„¡æ³•è®€å–æª”æ¡ˆ: {e}')
        return results

    results['raw_lines'] = len(lines)

    if len(lines) == 0:
        return results

    for line in lines:
        line = line.rstrip('\n')

        # æª¢æŸ¥ SyntaxErrorï¼ˆéæ¨™æº– log æ ¼å¼ï¼‰
        if RE_SYNTAX_ERROR.search(line) and '- ERROR -' not in line:
            results['errors'].append({
                'time': None,
                'type': 'SyntaxError',
                'message': line.strip(),
            })
            continue

        # æª¢æŸ¥æ³•äººè³‡æ–™ï¼ˆéæ¨™æº– log æ ¼å¼ï¼Œå‡ºç¾åœ¨ cron.logï¼‰
        m = RE_INSTITUTIONAL.search(line)
        if m and '- INFO -' not in line:
            # é€™æ˜¯ cron.log çš„ stdout è¼¸å‡º
            continue

        # è§£ææ¨™æº– log è¡Œ
        m = RE_LOG_LINE.match(line)
        if not m:
            continue

        date_str, time_str, level, message = m.groups()

        # æª¢æŸ¥ç¨‹å¼å•Ÿå‹•ï¼ˆstock_job log ç›´æ¥å¾ã€Œé–‹å§‹æŠ“å–åŸºæœ¬é¢è³‡æ–™ã€é–‹å§‹ï¼‰
        if 'é–‹å§‹æŠ“å–åŸºæœ¬é¢è³‡æ–™' in message and current_session is None:
            current_session = {
                'date': date_str,
                'start_time': time_str,
                'end_time': None,
                'phases': {
                    'fundamental': {
                        'stocks': [], 'errors': [], 'total_stocks': 0,
                        'price_ok': 0, 'price_missing': 0,
                    },
                    'news': {'stocks': [], 'total_news': 0, 'stock_prices': []},
                    'premarket': {'gpt_analyses': [], 'predicted_count': 0},
                    'monitoring': {
                        'iterations': 0, 'start_time': None, 'end_time': None,
                        'discord_notifications': 0, 'gpt_analyses': [],
                    },
                    'postmarket': {'accuracy': None},
                },
            }
            results['sessions'].append(current_session)
            continue

        if 'æ¯æ—¥è‚¡ç¥¨è³‡æ–™æŠ“å–ç¨‹å¼å•Ÿå‹•' in message:
            current_session = {
                'date': date_str,
                'start_time': time_str,
                'end_time': None,
                'phases': {
                    'fundamental': {
                        'stocks': [],
                        'errors': [],
                        'total_stocks': 0,
                        'price_ok': 0,
                        'price_missing': 0,
                    },
                    'news': {
                        'stocks': [],
                        'total_news': 0,
                        'stock_prices': [],
                    },
                    'premarket': {
                        'gpt_analyses': [],
                        'predicted_count': 0,
                    },
                    'monitoring': {
                        'iterations': 0,
                        'start_time': None,
                        'end_time': None,
                        'discord_notifications': 0,
                        'gpt_analyses': [],
                    },
                    'postmarket': {
                        'accuracy': None,
                    },
                },
            }
            results['sessions'].append(current_session)
            continue

        if current_session is None:
            # ç›¤å‰åˆ†æï¼ˆå¯èƒ½åœ¨å•Ÿå‹•å‰çš„ç¨ç«‹åŸ·è¡Œï¼‰
            if 'ç›¤å‰åˆ†æ' in message:
                if not results['sessions']:
                    current_session = {
                        'date': date_str,
                        'start_time': time_str,
                        'end_time': None,
                        'phases': {
                            'fundamental': {
                                'stocks': [], 'errors': [], 'total_stocks': 0,
                                'price_ok': 0, 'price_missing': 0,
                            },
                            'news': {'stocks': [], 'total_news': 0, 'stock_prices': []},
                            'premarket': {'gpt_analyses': [], 'predicted_count': 0},
                            'monitoring': {
                                'iterations': 0, 'start_time': None, 'end_time': None,
                                'discord_notifications': 0, 'gpt_analyses': [],
                            },
                            'postmarket': {'accuracy': None},
                        },
                    }
                    results['sessions'].append(current_session)
                else:
                    current_session = results['sessions'][-1]
            else:
                continue

        # è¨˜éŒ„ errors å’Œ warnings
        if level == 'ERROR':
            err = {'time': time_str, 'message': message}
            m_fetch = RE_FETCH_ERROR.match(message)
            if m_fetch:
                err['type'] = 'fetch_error'
                err['stock'] = m_fetch.group(1)
                err['detail'] = m_fetch.group(2)
                current_session['phases']['fundamental']['errors'].append(err)
            else:
                err['type'] = 'other'
            results['errors'].append(err)

        if level == 'WARNING':
            results['warnings'].append({
                'time': time_str,
                'message': message,
            })

        # === Phase: åŸºæœ¬é¢è³‡æ–™ ===
        m = RE_STOCK_PRICE.match(message)
        if m:
            idx, total, name, code, price = m.groups()
            current_session['phases']['fundamental']['total_stocks'] = int(total)
            has_price = price != '-'
            current_session['phases']['fundamental']['stocks'].append({
                'index': int(idx),
                'name': name,
                'code': code,
                'price': float(price) if has_price else None,
            })
            if has_price:
                current_session['phases']['fundamental']['price_ok'] += 1
            else:
                current_session['phases']['fundamental']['price_missing'] += 1

        # === Phase: æ–°èæ”¶é›† ===
        m = RE_NEWS_PROCESS.match(message)
        if m:
            idx, total, name, code = m.groups()
            current_session['phases']['news']['stocks'].append({
                'name': name,
                'code': code,
                'news_count': 0,
                'price': None,
                'change': None,
            })

        m = RE_NEWS_FOUND.search(message)
        if m:
            count = int(m.group(1))
            if current_session['phases']['news']['stocks']:
                current_session['phases']['news']['stocks'][-1]['news_count'] = count
                current_session['phases']['news']['total_news'] += count

        m = RE_STOCK_CHANGE.search(message)
        if m:
            price, change = float(m.group(1)), float(m.group(2))
            if current_session['phases']['news']['stocks']:
                current_session['phases']['news']['stocks'][-1]['price'] = price
                current_session['phases']['news']['stocks'][-1]['change'] = change
                current_session['phases']['news']['stock_prices'].append({
                    'name': current_session['phases']['news']['stocks'][-1]['name'],
                    'price': price,
                    'change': change,
                })

        # === Phase: ç›¤å‰åˆ†æ ===
        m = RE_GPT_ANALYSIS.search(message)
        if m:
            stock, sentiment, confidence = m.group(1), m.group(2), int(m.group(3))
            entry = {'stock': stock, 'sentiment': sentiment, 'confidence': confidence}
            if 'ç›¤å‰åˆ†æ' in message:
                current_session['phases']['premarket']['gpt_analyses'].append(entry)
            else:
                current_session['phases']['monitoring']['gpt_analyses'].append(entry)

        m = RE_PREMARKET_DONE.search(message)
        if m:
            current_session['phases']['premarket']['predicted_count'] = int(m.group(1))

        # === Phase: ç›£æ§ ===
        if 'é–‹å§‹å³æ™‚è‚¡åƒ¹ç›£æ§' in message:
            current_session['phases']['monitoring']['start_time'] = time_str

        m = RE_MONITOR_ITER.search(message)
        if m:
            current_session['phases']['monitoring']['iterations'] = int(m.group(1))

        m = RE_MONITOR_END.search(message)
        if m:
            current_session['phases']['monitoring']['iterations'] = int(m.group(1))
            current_session['phases']['monitoring']['end_time'] = time_str

        if 'å·²éæ”¶ç›¤æ™‚é–“' in message:
            current_session['phases']['monitoring']['end_time'] = time_str

        if RE_DISCORD.search(message):
            current_session['phases']['monitoring']['discord_notifications'] += 1

        # === Phase: ç›¤å¾Œ ===
        m = RE_POSTMARKET_ACC.search(message)
        if m:
            current_session['phases']['postmarket']['accuracy'] = float(m.group(1))

        if 'ä»Šæ—¥ä»»å‹™å®Œæˆ' in message:
            current_session['end_time'] = time_str

    return results


def parse_cron_log(filepath):
    """è§£æ cron.logï¼ˆæ··åˆæ¨™æº– log + stdout æ ¼å¼ï¼‰"""
    # cron.log çš„æ ¼å¼å’Œå…¶ä»– log ç›¸åŒï¼Œåªæ˜¯å°¾éƒ¨å¤šäº†ä¸€äº›éæ¨™æº–è¼¸å‡º
    return parse_log_file(filepath)


def format_report(all_results, target_date=None):
    """ç”¢ç”Ÿå¯è®€å ±å‘Š"""
    lines = []
    lines.append('=' * 70)
    lines.append('ğŸ“Š  æ¯æ—¥ Log åˆ†æå ±å‘Š')
    lines.append(f'    åˆ†ææ™‚é–“: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}')
    lines.append('=' * 70)

    # æŒ‰æ—¥æœŸæ•´ç†æ‰€æœ‰ sessionï¼ˆå»é‡ï¼‰
    sessions_by_date = defaultdict(list)
    seen_sessions = set()  # (date, start_time) å»é‡
    all_errors = []
    all_warnings = []
    seen_errors = set()
    seen_warnings = set()

    for result in all_results:
        for e in result['errors']:
            key = str(e)
            if key not in seen_errors:
                seen_errors.add(key)
                all_errors.append(e)
        for w in result['warnings']:
            key = f'{w["time"]}_{w["message"]}'
            if key not in seen_warnings:
                seen_warnings.add(key)
                all_warnings.append(w)
        for session in result['sessions']:
            d = session['date']
            if target_date and d != target_date:
                continue
            # å»é‡ï¼šåŒæ—¥æœŸåŒå•Ÿå‹•æ™‚é–“è¦–ç‚ºåŒä¸€ session
            session_key = (d, session['start_time'])
            if session_key in seen_sessions:
                continue
            seen_sessions.add(session_key)
            sessions_by_date[d].append({
                'session': session,
                'source': result['file'],
            })

    if not sessions_by_date:
        lines.append('\n[!] æ‰¾ä¸åˆ°ä»»ä½•åŸ·è¡Œè¨˜éŒ„')
        return '\n'.join(lines)

    for date in sorted(sessions_by_date.keys()):
        entries = sessions_by_date[date]
        lines.append(f'\n{"â”€" * 70}')
        lines.append(f'ğŸ“…  {date}  ({len(entries)} æ¬¡åŸ·è¡Œ)')
        lines.append(f'{"â”€" * 70}')

        for i, entry in enumerate(entries):
            s = entry['session']
            src = entry['source']
            # åˆ¤æ–·æ˜¯ cron æ’ç¨‹ é‚„æ˜¯æ‰‹å‹•æ¸¬è©¦
            start = s['start_time'] or ''
            if start >= '09:00' and start <= '14:00':
                run_type = 'æ’ç¨‹'
            elif start >= '00:00' and start < '09:00':
                run_type = 'å‡Œæ™¨æ¸¬è©¦'
            else:
                run_type = 'æ‰‹å‹•æ¸¬è©¦'
            lines.append(f'\n  â–¶ åŸ·è¡Œ #{i+1}  [{run_type}]  (ä¾†æº: {src})')
            lines.append(f'    å•Ÿå‹•: {s["start_time"] or "N/A"}  '
                         f'çµæŸ: {s["end_time"] or "æœªå®Œæˆ/æŒçºŒä¸­"}')

            # --- åŸºæœ¬é¢ ---
            fund = s['phases']['fundamental']
            if fund['total_stocks'] > 0 or fund['stocks']:
                total = fund['total_stocks'] or len(fund['stocks'])
                ok = fund['price_ok']
                missing = fund['price_missing']
                errs = len(fund['errors'])
                lines.append(f'\n    [åŸºæœ¬é¢æŠ“å–]')
                lines.append(f'      è‚¡ç¥¨æ•¸: {total}  |  æœ‰åƒ¹æ ¼: {ok}  |  '
                             f'ç„¡åƒ¹æ ¼($-): {missing}  |  éŒ¯èª¤: {errs}')
                if fund['errors']:
                    for e in fund['errors']:
                        lines.append(f'      âŒ {e["stock"]}: {e["detail"]}')
                if missing > 0:
                    no_price = [st['name'] for st in fund['stocks']
                                if st['price'] is None]
                    if no_price:
                        lines.append(f'      âš ï¸  ç„¡åƒ¹æ ¼: {", ".join(no_price[:10])}'
                                     + (f' ...ç­‰{len(no_price)}æª”' if len(no_price) > 10 else ''))

            # --- æ–°èæ”¶é›† ---
            news = s['phases']['news']
            if news['stocks']:
                total_news = news['total_news']
                stocks_with_news = sum(1 for st in news['stocks'] if st['news_count'] > 0)
                lines.append(f'\n    [æ–°èæ”¶é›†]')
                lines.append(f'      è™•ç†è‚¡ç¥¨: {len(news["stocks"])}  |  '
                             f'æœ‰æ–°è: {stocks_with_news}  |  '
                             f'æ–°èç¸½æ•¸: {total_news}')

                # æ¼²è·Œçµ±è¨ˆ
                if news['stock_prices']:
                    up = [p for p in news['stock_prices'] if p['change'] > 0]
                    down = [p for p in news['stock_prices'] if p['change'] < 0]
                    flat = [p for p in news['stock_prices'] if p['change'] == 0]
                    lines.append(f'      è‚¡åƒ¹: ä¸Šæ¼² {len(up)}  |  '
                                 f'ä¸‹è·Œ {len(down)}  |  å¹³ç›¤ {len(flat)}')

                    if down:
                        worst = sorted(down, key=lambda x: x['change'])[:3]
                        worst_str = ', '.join(
                            f'{w["name"]}({w["change"]:+.2f}%)' for w in worst)
                        lines.append(f'      è·Œå¹…å‰ä¸‰: {worst_str}')
                    if up:
                        best = sorted(up, key=lambda x: -x['change'])[:3]
                        best_str = ', '.join(
                            f'{b["name"]}({b["change"]:+.2f}%)' for b in best)
                        lines.append(f'      æ¼²å¹…å‰ä¸‰: {best_str}')

            # --- ç›¤å‰åˆ†æ ---
            pre = s['phases']['premarket']
            if pre['predicted_count'] > 0 or pre['gpt_analyses']:
                lines.append(f'\n    [ç›¤å‰åˆ†æ]')
                lines.append(f'      é æ¸¬è‚¡ç¥¨æ•¸: {pre["predicted_count"]}')
                if pre['gpt_analyses']:
                    sentiments = defaultdict(int)
                    for g in pre['gpt_analyses']:
                        sentiments[g['sentiment']] += 1
                    sent_str = ', '.join(f'{k}: {v}' for k, v in sentiments.items())
                    lines.append(f'      GPT æƒ…ç·’åˆ†ä½ˆ: {sent_str}')
                    # éä¸­æ€§çš„ç„¦é»åˆ†æ
                    non_neutral = [g for g in pre['gpt_analyses']
                                   if g['sentiment'] != 'ä¸­æ€§']
                    if non_neutral:
                        for g in non_neutral:
                            lines.append(
                                f'      ğŸ¯ {g["stock"]}: {g["sentiment"]} '
                                f'({g["confidence"]}%)')

            # --- å³æ™‚ç›£æ§ ---
            mon = s['phases']['monitoring']
            if mon['iterations'] > 0 or mon['start_time']:
                lines.append(f'\n    [å³æ™‚ç›£æ§]')
                lines.append(f'      æ™‚é–“: {mon["start_time"] or "N/A"} ~ '
                             f'{mon["end_time"] or "N/A"}')
                lines.append(f'      è¿­ä»£æ¬¡æ•¸: {mon["iterations"]}  |  '
                             f'Discord é€šçŸ¥: {mon["discord_notifications"]}')

                # ç›£æ§æœŸé–“ GPT åˆ†æçµ±è¨ˆ
                if mon['gpt_analyses']:
                    mon_sentiments = defaultdict(int)
                    for g in mon['gpt_analyses']:
                        mon_sentiments[g['sentiment']] += 1
                    non_neutral_mon = [g for g in mon['gpt_analyses']
                                       if g['sentiment'] != 'ä¸­æ€§']
                    if non_neutral_mon:
                        lines.append(f'      ç›£æ§æœŸé–“ GPT éä¸­æ€§ä¿¡è™Ÿ:')
                        # å»é‡ï¼ˆåŒä¸€è‚¡å¯èƒ½å¤šæ¬¡åˆ†æï¼‰
                        seen = set()
                        for g in non_neutral_mon:
                            key = f'{g["stock"]}_{g["sentiment"]}'
                            if key not in seen:
                                seen.add(key)
                                lines.append(
                                    f'        ğŸ”” {g["stock"]}: '
                                    f'{g["sentiment"]} ({g["confidence"]}%)')

            # --- ç›¤å¾Œåˆ†æ ---
            post = s['phases']['postmarket']
            if post['accuracy'] is not None:
                lines.append(f'\n    [ç›¤å¾Œåˆ†æ]')
                acc = post['accuracy']
                emoji = 'âœ…' if acc >= 50 else 'âš ï¸' if acc >= 40 else 'âŒ'
                lines.append(f'      æ–¹å‘æº–ç¢ºç‡: {acc}% {emoji}')

    # === éŒ¯èª¤åŒ¯ç¸½ ===
    if all_errors:
        lines.append(f'\n{"â”€" * 70}')
        lines.append('âš ï¸  éŒ¯èª¤åŒ¯ç¸½')
        lines.append(f'{"â”€" * 70}')

        # åˆ†é¡çµ±è¨ˆ
        error_types = defaultdict(list)
        for e in all_errors:
            if isinstance(e, dict):
                etype = e.get('type', 'other')
                error_types[etype].append(e)
            else:
                error_types['raw'].append(e)

        for etype, errors in error_types.items():
            if etype == 'SyntaxError':
                lines.append(f'\n  SyntaxError ({len(errors)} æ¬¡):')
                for e in errors:
                    lines.append(f'    {e["message"][:80]}')
            elif etype == 'fetch_error':
                # çµ±è¨ˆå“ªäº›è‚¡ç¥¨æœ€å¸¸å¤±æ•—
                stock_fails = defaultdict(list)
                for e in errors:
                    stock_fails[e['stock']].append(e['detail'])
                lines.append(f'\n  è‚¡åƒ¹æŠ“å–å¤±æ•— ({len(errors)} æ¬¡):')
                for stock, details in stock_fails.items():
                    unique_reasons = set(details)
                    lines.append(f'    {stock}: {len(details)} æ¬¡ '
                                 f'(åŸå› : {", ".join(unique_reasons)})')
            elif etype == 'other':
                lines.append(f'\n  å…¶ä»–éŒ¯èª¤ ({len(errors)} æ¬¡):')
                for e in errors[:5]:
                    msg = e['message'] if isinstance(e, dict) else str(e)
                    lines.append(f'    [{e.get("time", "?")}] {msg[:80]}')
            elif etype == 'raw':
                lines.append(f'\n  éæ¨™æº–éŒ¯èª¤ ({len(errors)} æ¬¡):')
                for e in errors[:3]:
                    lines.append(f'    {str(e)[:80]}')

    # === è­¦å‘ŠåŒ¯ç¸½ ===
    if all_warnings:
        lines.append(f'\n{"â”€" * 70}')
        lines.append(f'âš¡ è­¦å‘ŠåŒ¯ç¸½ ({len(all_warnings)} å‰‡)')
        lines.append(f'{"â”€" * 70}')
        for w in all_warnings:
            lines.append(f'  [{w["time"]}] {w["message"][:70]}')

    # === å•é¡Œæ¸…å–® ===
    lines.append(f'\n{"â”€" * 70}')
    lines.append('ğŸ”  ç™¼ç¾çš„å•é¡Œ')
    lines.append(f'{"â”€" * 70}')
    issues = []

    # æª¢æŸ¥é‡è¤‡åŸ·è¡Œ
    for date, entries in sessions_by_date.items():
        if len(entries) > 1:
            times = [e['session']['start_time'] for e in entries
                     if e['session']['start_time']]
            issues.append(f'[é‡è¤‡åŸ·è¡Œ] {date} æœ‰ {len(entries)} æ¬¡åŸ·è¡Œ '
                          f'(å•Ÿå‹•æ™‚é–“: {", ".join(times)})')

    # æª¢æŸ¥ç¾¤è¯ä¸€ç›´å¤±æ•—
    phunion_fails = sum(
        1 for e in all_errors
        if isinstance(e, dict) and e.get('stock') == 'ç¾¤è¯'
    )
    if phunion_fails > 0:
        issues.append(f'[æŒçºŒéŒ¯èª¤] ç¾¤è¯(8299) æŠ“å–æŒçºŒå¤±æ•— '
                      f'({phunion_fails} æ¬¡)ï¼Œéœ€æª¢æŸ¥ GoodInfo é é¢æ ¼å¼')

    # æª¢æŸ¥å¤§é‡ç„¡åƒ¹æ ¼
    for date, entries in sessions_by_date.items():
        for entry in entries:
            fund = entry['session']['phases']['fundamental']
            if fund['price_missing'] > 20:
                issues.append(f'[è³‡æ–™ç¼ºå¤±] {date} {entry["session"]["start_time"]} '
                              f'åŸ·è¡Œæ™‚ {fund["price_missing"]} æª”ç„¡åƒ¹æ ¼'
                              f'ï¼ˆå¯èƒ½åœ¨éäº¤æ˜“æ™‚é–“åŸ·è¡Œï¼‰')

    # æª¢æŸ¥æ–°è 0 å‰‡
    for date, entries in sessions_by_date.items():
        for entry in entries:
            news = entry['session']['phases']['news']
            if news['stocks'] and news['total_news'] == 0:
                issues.append(f'[ç„¡æ–°è] {date} {entry["session"]["start_time"]} '
                              f'æ‰€æœ‰è‚¡ç¥¨éƒ½æ²’æœ‰æŠ“åˆ°æ–°è')

    # æª¢æŸ¥æº–ç¢ºç‡ä½ï¼ˆæ¯æ—¥åªå ±ä¸€æ¬¡æœ€ä½çš„ï¼‰
    for date, entries in sessions_by_date.items():
        low_accs = []
        for entry in entries:
            acc = entry['session']['phases']['postmarket']['accuracy']
            if acc is not None and acc < 40:
                low_accs.append(acc)
        if low_accs:
            worst = min(low_accs)
            issues.append(f'[ä½æº–ç¢ºç‡] {date} ç›¤å¾Œæ–¹å‘æº–ç¢ºç‡æœ€ä½åªæœ‰ {worst}%')

    # æª¢æŸ¥ 2/5 NoneType å…¨é¢å¤±æ•—
    nonetype_fails = sum(
        1 for e in all_errors
        if isinstance(e, dict) and e.get('type') == 'fetch_error'
        and 'NoneType' in e.get('detail', '')
    )
    if nonetype_fails > 5:
        issues.append(f'[API ç•°å¸¸] GoodInfo API å…¨é¢å¤±æ•— '
                      f'({nonetype_fails} æ¬¡)ï¼Œå¯èƒ½è¢«å°é–æˆ–ç¶²ç«™æ”¹ç‰ˆ')

    if issues:
        for issue in issues:
            lines.append(f'  â€¢ {issue}')
    else:
        lines.append('  âœ… æœªç™¼ç¾æ˜é¡¯å•é¡Œ')

    lines.append(f'\n{"=" * 70}')
    lines.append('å ±å‘ŠçµæŸ')
    lines.append(f'{"=" * 70}')

    return '\n'.join(lines)


def main():
    target_date = None
    latest_only = False

    if len(sys.argv) > 1:
        arg = sys.argv[1]
        if arg == '--latest':
            latest_only = True
        elif re.match(r'^\d{4}-\d{2}-\d{2}$', arg):
            target_date = arg
        else:
            print(f'ç”¨æ³•: python {sys.argv[0]} [YYYY-MM-DD | --latest]')
            sys.exit(1)

    # æ”¶é›†æ‰€æœ‰ log æª”æ¡ˆ
    log_files = sorted(glob.glob(os.path.join(LOG_DIR, '*.log')))

    if not log_files:
        print(f'[!] åœ¨ {LOG_DIR} æ‰¾ä¸åˆ°ä»»ä½• log æª”æ¡ˆ')
        sys.exit(1)

    if latest_only:
        # åªå–æœ€æ–°æœ‰å…§å®¹çš„ log
        log_files = [f for f in log_files if os.path.getsize(f) > 0]
        if log_files:
            log_files = [log_files[-1]]

    # è§£ææ‰€æœ‰ log
    all_results = []
    for filepath in log_files:
        if os.path.getsize(filepath) == 0:
            continue
        result = parse_log_file(filepath)
        all_results.append(result)

    # ç”¢ç”Ÿå ±å‘Š
    report = format_report(all_results, target_date)
    print(report)

    # å„²å­˜å ±å‘Š
    report_file = os.path.join(LOG_DIR, 'analysis_report.txt')
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write(report)
    print(f'\n(å ±å‘Šå·²å„²å­˜è‡³ {report_file})')


if __name__ == '__main__':
    main()
